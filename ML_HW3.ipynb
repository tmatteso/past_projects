{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f627ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 3) (208, 879)\n",
      "(10, 3) (10, 879)\n",
      "(879,)\n",
      "(3,)\n",
      "[[ 0.0765  0.001  -0.013 ]\n",
      " [-0.0906 -0.0305 -0.1173]\n",
      " [ 0.3749  0.2848  0.238 ]\n",
      " [ 0.2756  0.1082  0.1791]\n",
      " [ 0.2612  0.2003  0.1468]\n",
      " [ 0.0284  0.0293  0.0047]\n",
      " [-0.065   0.0675  0.0309]\n",
      " [ 0.0626  0.0351 -0.0085]\n",
      " [ 0.0233 -0.01    0.0247]\n",
      " [ 0.0104  0.0485 -0.103 ]]\n",
      "(3, 10, 10)\n",
      "(10, 879)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "# import test_mean.txt\n",
    "test_means = np.loadtxt(open(\"test_mean.txt\", \"r\"))\n",
    "# hip1000.txt\n",
    "expression = np.loadtxt(open(\"hip1000.txt\", \"r\"), delimiter=\",\")\n",
    "print(test_means.shape, expression.shape)\n",
    "test_means = test_means[:10, ]\n",
    "expression = expression[:10, :]\n",
    "print(test_means.shape, expression.shape)\n",
    "print((expression[0, :]).shape)\n",
    "means = test_means\n",
    "# 10x10\n",
    "covariances = np.array(3*[np.identity(test_means.shape[0])])\n",
    "# mixing proportions --prob_of_c\n",
    "prob_of_c = np.array([0.3, 0.3, 0.4])\n",
    "data = expression.copy()\n",
    "print(prob_of_c.shape)\n",
    "print(means)\n",
    "print(covariances.shape)\n",
    "print(data.shape)\n",
    "print(data[:, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e79c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(data, means, covariances, prob_of_c):\n",
    "    # 10x879, 10x3, 3x10x10, 3x1\n",
    "    hidden_matrix = [] \n",
    "    p_data_given_c = []\n",
    "    \n",
    "    for i in range(means.shape[1]):\n",
    "        intermed_ls = []\n",
    "        intermed_ls_2 = []\n",
    "        for j in range(data.shape[1]):\n",
    "            first_term = linalg.det(2*np.pi*covariances[i]) **(-1/2)\n",
    "            data_minus_mean = (np.reshape((data[:,j]-means[:,i]), (1,10)) )\n",
    "            second_term = (data_minus_mean @ linalg.inv(covariances[i]) @ data_minus_mean.T).item() * (-1/2)\n",
    "            p_x_given_c_i = (first_term*np.exp(second_term))\n",
    "            intermed_ls.append(p_x_given_c_i)\n",
    "            intermed_ls_2.append(p_x_given_c_i*prob_of_c[i])\n",
    "        p_data_given_c.append(intermed_ls)\n",
    "        hidden_matrix.append(intermed_ls_2)\n",
    "    # 3x879\n",
    "    # 879x1\n",
    "    p_data_given_c = np.array(p_data_given_c).T\n",
    "    hidden_matrix = np.array(hidden_matrix)\n",
    "    bottom = np.array([p_data_given_c[i,:] @ prob_of_c for i in range(p_data_given_c.shape[0])])\n",
    "    for i in range(means.shape[1]):\n",
    "        hidden_matrix[i] = hidden_matrix[i] / bottom\n",
    "#     #print(p_data_given_c.shape, \"should be 879x3\")\n",
    "#     # h matrix is wrong\n",
    "#     hidden_matrix = [] #np.ones((879,3))\n",
    "#     # need to correct bottom\n",
    "    \n",
    "    #print(\"p_data_given_c\", p_data_given_c.shape)\n",
    "    #print(\"prob_of_c\", prob_of_c)\n",
    "    #print(\"hidden_matrix\", hidden_matrix.shape)\n",
    "    #print(hidden_matrix.shape, \"should be 879x3\")\n",
    "    return p_data_given_c,hidden_matrix.T\n",
    "\n",
    "def get_log_likelihood(prob_of_c, prob_of_x_given_c):\n",
    "#     prob_of_c = np.reshape(prob_of_c, (prob_of_c.shape[0],1))\n",
    "    #print(prob_of_x_given_c.shape, prob_of_c.shape)\n",
    "    log_likelihood = 0\n",
    "    for i in range(prob_of_x_given_c.shape[0]):\n",
    "        intermed_ls = 0\n",
    "        for j in range(prob_of_c.shape[0]):\n",
    "            intermed_ls += prob_of_x_given_c[i,j]*prob_of_c[j] \n",
    "        log_likelihood += np.log(intermed_ls)\n",
    "\n",
    "    return log_likelihood\n",
    "\n",
    "def M_step(data, hidden_matrix):\n",
    "    N = data.shape[1]\n",
    "#     print(N)\n",
    "    # \"should be 879x3\", sum along the first axis\n",
    "    # the hidden matrix is wrong, the probs should not sum to one immediately\n",
    "    prob_of_c = np.sum(hidden_matrix, axis=0)/N\n",
    "    # these should sum to 1\n",
    "    #print(prob_of_c, \"prob of c\")\n",
    "    # means \n",
    "    means = []\n",
    "    for i in range(hidden_matrix.shape[1]):\n",
    "        # check shape \n",
    "        hidden_matrix_i = np.reshape(hidden_matrix[:, i], (hidden_matrix.shape[0], 1))\n",
    "        mean_i = (data @ hidden_matrix_i)/ np.sum(hidden_matrix[:, i], axis=0)\n",
    "        means.append(mean_i)\n",
    "    means = np.column_stack(means)\n",
    "    #print(means.shape, \"mean\")\n",
    "    # covariances\n",
    "    covariances = []\n",
    "    # 10x879 879x10 1x3 -- then does this across all data points 3\n",
    "    # each cluster\n",
    "    for i in range(hidden_matrix.shape[1]):\n",
    "        # each datapoint\n",
    "        intermediate_ls = []\n",
    "        for j in range(hidden_matrix.shape[0]):\n",
    "            datapoint = data[:,j] #10x879\n",
    "            mean_i = means[:,i]\n",
    "            data_minus_mean = datapoint - mean_i\n",
    "            data_minus_mean = (np.reshape(data_minus_mean, (10, 1)))\n",
    "            ele = data_minus_mean @ data_minus_mean.T * hidden_matrix[j, i] # 10x10\n",
    "            intermediate_ls.append(ele)\n",
    "        intermediate_ls = np.dstack(intermediate_ls)\n",
    "        #print(np.sum(intermediate_ls, axis=2), \"shloop\")\n",
    "        #print(np.sum(hidden_matrix[:, i], axis=0), \"poop\")\n",
    "        covariances.append(np.sum(intermediate_ls, axis=2) / np.sum(hidden_matrix[:, i], axis=0))\n",
    "    covariances = np.array(covariances) \n",
    "    #print(covariances.shape, \"covariance\")\n",
    "    return prob_of_c, means, covariances\n",
    "        \n",
    "p_data_given_c, hidden_matrix = E_step(data, means, covariances, prob_of_c)    \n",
    "#print(get_log_likelihood(prob_of_c, p_data_given_c))\n",
    "#print(hidden_matrix, \"HIDDEN\")\n",
    "prob_of_c_1, means_1, covariances_1 = M_step(data, hidden_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44246eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_M_algo(prob_of_c, means, covariances, data, conv_thresh):\n",
    "    log_likelihoods = []\n",
    "    i = 0\n",
    "    # now start the while loop\n",
    "    while (i < 3) or ((log_likelihoods[i-1] - log_likelihoods[i-2]) > conv_thresh):\n",
    "        # not using the new params!\n",
    "        p_data_given_c, hidden_matrix = E_step(data, means, covariances, prob_of_c)\n",
    "        prob_of_c, means, covariances = M_step(data, hidden_matrix)\n",
    "        #print(\"hidden\", hidden_matrix[:,0])\n",
    "        #print(\"covariances\", covariances[0,:,:])\n",
    "        #print(prob_of_c)\n",
    "        log_likelihood = get_log_likelihood(prob_of_c, p_data_given_c)\n",
    "        log_likelihoods.append(log_likelihood)\n",
    "        i += 1\n",
    "    return(log_likelihoods, hidden_matrix, p_data_given_c)\n",
    "    \n",
    "conv_thresh = 0.001\n",
    "log_likelihoods, hidden_matrix, p_data_given_c = E_M_algo(prob_of_c, means, covariances, data, conv_thresh)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(len(log_likelihoods))], log_likelihoods)\n",
    "plt.title(\"Log Likelihood for K=3 with given initial centers\")\n",
    "plt.xlabel(\"number of iterations\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "plt.savefig(\"3a.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81758323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[3.85944833e-05 1.25086262e-01 8.74875144e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(hidden_matrix[0].shape)\n",
    "N = data.shape[1]\n",
    "prob_of_c = hidden_matrix[0]\n",
    "print(prob_of_c)\n",
    "print(np.sum(prob_of_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad0608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10340.527106915102\n",
      "-10307.64187787189\n",
      "-10334.177243815871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/ytzggnn50y3gt2z3d8dh6bm80000gn/T/ipykernel_2814/2053794297.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  first_term = linalg.det(2*np.pi*covariances[i]) **(-1/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10317.775438424296\n",
      "-10323.230613067317\n",
      "-10317.501010040458\n",
      "-10360.793964925024\n",
      "-10316.021247120898\n",
      "-10526.337337187588\n",
      "-10564.175683938727\n",
      "[-10340.527106915102, -10307.64187787189, -10334.177243815871, -10317.775438424296, -10323.230613067317, -10317.501010040458, -10360.793964925024, -10316.021247120898, -10526.337337187588, -10564.175683938727]\n"
     ]
    }
   ],
   "source": [
    "#For K = 3, try 10 different random initializations for all parameters\n",
    "def random_inits(data, k):\n",
    "    # prob of c -- 3x1 -- must sum to 1\n",
    "    r = [np.random.random() for i in range(k)]\n",
    "    s = sum(r)\n",
    "    r = np.array([ i/s for i in r ])\n",
    "    prob_of_c = r\n",
    "    #print((prob_of_c))\n",
    "    #print(sum(((prob_of_c))))\n",
    "    # mean -- 10x3\n",
    "    means = np.random.rand(10, k)\n",
    "    #print(means)\n",
    "    # covariance -- 3x10x10\n",
    "    identities = np.array(k*[np.identity(test_means.shape[0])])\n",
    "    epsilon = 0.001\n",
    "    covariances = []\n",
    "    for i in range(k):\n",
    "        covariance = (np.random.rand((10))*identities[i]) + epsilon\n",
    "        covariances.append(covariance)\n",
    "    covariances = np.dstack(covariances).T\n",
    "    \n",
    "    return prob_of_c, means, covariances\n",
    "\n",
    "#  must do this 10 times for this one\n",
    "def sim_for_k(number_of_simulations, data, k):\n",
    "    out = []\n",
    "    np.seterr(over='raise')\n",
    "    for i in range(number_of_simulations):\n",
    "        while True:\n",
    "            try:\n",
    "                prob_of_c, means, covariances = random_inits(data, k)\n",
    "                log_likelihoods, hidden_matrix, p_data_given_c = E_M_algo(prob_of_c, means, covariances, data, conv_thresh)        \n",
    "                print(log_likelihoods[-1])\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        out.append(log_likelihoods[-1])\n",
    "    print(out)\n",
    "\n",
    "sim_for_k(10, data, 3)\n",
    "# What is the data log-likelihood at convergence for each initialization?\n",
    "# [Hint: There should be 10 values]. Which one do you think was the best initialization among the 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a7401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10331.905353771952\n",
      "-10316.255578693012\n",
      "-10545.764027870982\n",
      "-10318.452892839241\n",
      "-10324.657959419206\n",
      "-10304.48330494598\n",
      "-10326.651483792553\n",
      "-10305.283894324604\n",
      "-10520.658438596858\n",
      "-10332.024809210769\n",
      "-4844.957359364966\n",
      "-10224.606917285313\n",
      "-10251.366051790452\n",
      "-10222.022187425153\n",
      "-10221.378910112242\n",
      "-10228.603673647407\n",
      "-10249.958691039565\n",
      "-10247.806343740773\n",
      "-10226.924003008171\n",
      "-10224.354728761333\n",
      "-10213.956607690941\n",
      "-4196.19890241876\n",
      "-10140.287474859566\n",
      "-10204.255814379285\n",
      "-10154.031085207425\n",
      "-10181.39830009955\n",
      "-10183.143026443156\n",
      "-10173.350386834909\n",
      "-10174.51082856208\n",
      "-10176.000176043197\n",
      "-10170.677897900887\n",
      "-10166.088548960272\n",
      "-4663.086072617946\n",
      "-10079.795944571903\n",
      "-10108.774704591038\n",
      "-10064.607894485982\n",
      "-10086.32381149467\n",
      "-10114.556932040834\n",
      "-10124.737863447668\n",
      "-10079.568326308892\n",
      "-10056.831829545685\n",
      "-10104.2750789858\n",
      "-10067.690783351454\n",
      "-4611.132910676744\n",
      "-9993.69075999873\n",
      "-10010.393066162847\n",
      "-10028.000522947004\n",
      "-10050.86210502862\n",
      "-10028.724734581705\n",
      "-9997.338409015561\n",
      "-10029.834968482697\n",
      "-10018.695305036863\n",
      "-9993.700944013426\n",
      "-10011.883974105263\n",
      "-4377.787098945613\n",
      "-9932.216181440757\n",
      "-9954.683865607954\n",
      "-9973.444158505074\n",
      "-9979.445683779732\n",
      "-9971.666145430503\n",
      "-9918.451695022288\n",
      "-9929.244953038493\n",
      "-9900.31857907139\n",
      "-9977.632793066334\n",
      "-9973.105405647575\n",
      "-4635.408267494842\n",
      "-9852.577353710869\n",
      "-9911.090161557328\n",
      "-9878.862222608457\n",
      "-9884.791016171319\n",
      "-9864.22417766683\n",
      "-9916.109464766427\n",
      "-9876.098781411922\n",
      "-9880.538716705447\n",
      "-9874.604930710324\n",
      "-9915.771912958508\n",
      "-4652.30342674487\n",
      "-9845.185700218786\n",
      "-9789.711982694931\n",
      "-9824.342943958676\n",
      "-9845.289296765925\n",
      "-9799.668737577384\n",
      "-9809.110665779897\n",
      "-9820.294106219051\n",
      "-9833.826125291134\n",
      "-9790.286008556137\n",
      "-9818.658197821642\n",
      "-4592.913971263783\n"
     ]
    }
   ],
   "source": [
    "def simulate_me(number_of_simulations, data):\n",
    "    # init the split in the beginning -- 10, 879\n",
    "    train, test = data[:,:600], data[:,600:]\n",
    "    ll_ls = []\n",
    "    # obviously this was not worth it-- you just got unlucky\n",
    "    np.seterr(all='raise')\n",
    "    for k in range(3, 11):\n",
    "        test_ls = []\n",
    "        for i in range(number_of_simulations):\n",
    "            while True:\n",
    "                try:\n",
    "                    prob_of_c, means, covariances = random_inits(data, k)\n",
    "                    log_likelihoods, hidden_matrix, p_data_given_c = E_M_algo(prob_of_c, means, covariances, data, conv_thresh)        \n",
    "                    print(log_likelihoods[-1])\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "            # eval on test\n",
    "            N = train.shape[1]\n",
    "            #print(hidden_matrix.shape, N)\n",
    "            prob_of_c = np.sum(hidden_matrix, axis=0)/N\n",
    "            p_data_given_c, hidden_matrix = E_step(test, means, covariances, prob_of_c)\n",
    "            test_ls.append(get_log_likelihood(prob_of_c, p_data_given_c))\n",
    "        #print(test_ls)\n",
    "        keep_ll = np.max(test_ls)\n",
    "        print(keep_ll)\n",
    "        ll_ls.append(keep_ll)\n",
    "        \n",
    "    plt.plot([i+3 for i in range(len(ll_ls))], ll_ls)\n",
    "    plt.title(\"Log Likelihood for K from 3 to 10 with random initial centers\")\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Best Test Log Likelihood\")\n",
    "    #plt.show()\n",
    "    plt.savefig(\"3d.png\")\n",
    "    plt.close()\n",
    "            \n",
    "            \n",
    "                \n",
    "number_of_simulations = 10         \n",
    "simulate_me(number_of_simulations, data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90426e53",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compute the likelihood of the held-out (validation) data to determine which model (number of clusters) is more accurate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
